{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0c3uigjxcCkN",
        "outputId": "ec71338d-bfb7-4a79-fbb6-1cfd09535789"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\tanuj\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\tanuj\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file  \n",
            "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\tanuj\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import shutil\n",
        "!pip install split-folders -q\n",
        "!pip install ultralytics -q\n",
        "import splitfolders\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neN716xdMkwS"
      },
      "source": [
        "# Download the Dataset & Copy Files to Desired Destination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9zgiP4_ZiD",
        "outputId": "d1812c4f-185c-4a60-ee01-c58aed2af072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/a2015003713/militaryaircraftdetectiondataset?dataset_version_number=90...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10.1G/10.1G [08:05<00:00, 22.4MB/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: C:\\Users\\tanuj\\.cache\\kagglehub\\datasets\\a2015003713\\militaryaircraftdetectiondataset\\versions\\90\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"a2015003713/militaryaircraftdetectiondataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3ae9079",
        "outputId": "16578392-4a47-44af-dca7-746088f95cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied F15 to /content/dataset/\n",
            "Copied F16 to /content/dataset/\n",
            "Copied F18 to /content/dataset/\n",
            "Copying complete.\n"
          ]
        }
      ],
      "source": [
        "source_dir = f'{path}/crop/'\n",
        "destination_dir = '/content/dataset/'\n",
        "subfolders_to_copy = ['F15', 'F16', 'F18']\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Copy each specified subfolder\n",
        "for folder in subfolders_to_copy:\n",
        "    source_path = os.path.join(source_dir, folder)\n",
        "    destination_path = os.path.join(destination_dir, folder)\n",
        "    if os.path.exists(source_path):\n",
        "        shutil.copytree(source_path, destination_path)\n",
        "        print(f\"Copied {folder} to {destination_dir}\")\n",
        "    else:\n",
        "        print(f\"Source folder {folder} not found in {source_dir}\")\n",
        "        raise FileNotFoundError\n",
        "\n",
        "print(\"Copying complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKCA6oJMMyi6"
      },
      "source": [
        "# Label Files & Transfer Images to a Single Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7ZM8RPpKFmr",
        "outputId": "0905a6e3-b61d-4793-9cb6-154333b73d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▶️ Reading images from: /content/dataset/F15\n",
            "------------------------------\n",
            "▶️ Reading images from: /content/dataset/F16\n",
            "------------------------------\n",
            "▶️ Reading images from: /content/dataset/F18\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "aircrafts = [\"F15\", \"F16\", \"F18\"]\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "\n",
        "for i, aircraft in enumerate(aircrafts):\n",
        "\n",
        "  image_directory = f\"/content/dataset/{aircraft}\"\n",
        "  label_directory = \"/content/dataset/labels\"\n",
        "  CLASS_ID = i\n",
        "\n",
        "  os.makedirs(label_directory, exist_ok=True)\n",
        "\n",
        "  yolo_label_content = f\"{CLASS_ID} 0.5 0.5 1.0 1.0\"\n",
        "\n",
        "  print(f\"▶️ Reading images from: {image_directory}\")\n",
        "  print(\"-\" * 30)\n",
        "\n",
        "  if not os.path.isdir(image_directory):\n",
        "      continue\n",
        "  else:\n",
        "      for filename in os.listdir(image_directory):\n",
        "          if os.path.splitext(filename)[1].lower() in image_extensions:\n",
        "              label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "              label_filepath = os.path.join(label_directory, label_filename)\n",
        "              try:\n",
        "                  with open(label_filepath, 'w') as f:\n",
        "                      f.write(yolo_label_content)\n",
        "              except IOError as e:\n",
        "                  print(f\"❌ Error creating label for {filename}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQnOWb2pMh8j",
        "outputId": "9728b429-8982-40be-cc1a-eec5521890a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting image transfer to a single folder...\n",
            "Processing images from: /content/dataset/F15\n",
            "Processing images from: /content/dataset/F16\n",
            "Processing images from: /content/dataset/F18\n",
            "Image transfer complete.\n"
          ]
        }
      ],
      "source": [
        "# Create the destination directory for all images if it doesn't exist\n",
        "all_images_destination_dir = '/content/dataset/images/'\n",
        "os.makedirs(all_images_destination_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "print(\"Starting image transfer to a single folder...\")\n",
        "for aircraft in aircrafts:\n",
        "    source_image_directory = f\"/content/dataset/{aircraft}\"\n",
        "    print(f\"Processing images from: {source_image_directory}\")\n",
        "    if os.path.isdir(source_image_directory):\n",
        "        for filename in os.listdir(source_image_directory):\n",
        "            if os.path.splitext(filename)[1].lower() in image_extensions:\n",
        "                source_filepath = os.path.join(source_image_directory, filename)\n",
        "                destination_filepath = os.path.join(all_images_destination_dir, filename)\n",
        "                try:\n",
        "                    # Use shutil.move to move the file\n",
        "                    shutil.move(source_filepath, destination_filepath)\n",
        "                    # print(f\"Moved {filename} to {all_images_destination_dir}\")\n",
        "                except IOError as e:\n",
        "                    print(f\"❌ Error moving {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"Source directory not found: {source_image_directory}\")\n",
        "\n",
        "print(\"Image transfer complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjHIlg13OdUF",
        "outputId": "13267120-14ca-4c6b-8035-43c6d86d2697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted folder: /content/dataset/F15\n",
            "Deleted folder: /content/dataset/F16\n",
            "Deleted folder: /content/dataset/F18\n"
          ]
        }
      ],
      "source": [
        "for aircraft in aircrafts:\n",
        "    folder_path = f\"/content/dataset/{aircraft}\"\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f\"Deleted folder: {folder_path}\")\n",
        "    else:\n",
        "        print(f\"Folder not found or not a directory: {folder_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnW14DFoRGmQ"
      },
      "source": [
        "# Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmfej2y2RFW9",
        "outputId": "592d6e85-4de3-46ca-bd61-8140be1408dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 9990 files [00:46, 215.37 files/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset splitting complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "input_folder = '/content/dataset/'\n",
        "\n",
        "output_folder = '/content/split/'\n",
        "\n",
        "splitfolders.ratio(input_folder,\n",
        "                   output=output_folder,\n",
        "                   seed=42,\n",
        "                   ratio=(.8, .2),\n",
        "                   group_prefix=None,\n",
        "                   move=False) # Set to True to move files instead of copying\n",
        "\n",
        "print(\"Dataset splitting complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IsjHFLDk-cBM"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "dataset_yaml = '/content/dataset.yaml'\n",
        "data = {\n",
        "        \"train\": \"/content/split/train/images\",\n",
        "        \"val\": \"/content/split/val/images\",\n",
        "        \"names\":  [\"F15\", \"F16\", \"F18\"],\n",
        "        \"nc\": 3\n",
        "    }\n",
        "\n",
        "try:\n",
        "    with open(dataset_yaml, 'w') as f:\n",
        "        yaml.dump(data, f, default_flow_style=False)\n",
        "except IOError as e:\n",
        "    print(f\"❌ Error creating label for {dataset_yaml}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ufFbFQlT0-r"
      },
      "source": [
        "Create this dataset.yaml:\n",
        "\n",
        "train: /content/split/train/images\n",
        "\n",
        "val: /content/split/val/images\n",
        "\n",
        "nc: 9\n",
        "\n",
        "names: [\"F15\", \"F16\", \"F18\", \"F22\", \"F35\", \"B1\", \"B2\", \"C17\", \"C130\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wcCB0AEUVF8"
      },
      "source": [
        "# Fine-Tune the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PPzjLXk553G"
      },
      "source": [
        "## Test Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOpuaOA2jV22",
        "outputId": "2247b32d-9bb2-4155-af7f-6deeed798ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 18.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\tanuj\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 8.76MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 314.4366.0 MB/s, size: 834.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\content\\split\\train\\labels... 3989 images, 0 backgrounds, 7 corrupt: 100%|██████████| 3996/3996 [00:07<00:00, 501.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\2957729725f0acb08acb86af5e28c5f3_0.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\8a0b8bad3da60ee3b07c0c7b5cd65213_1.jpg: ignoring corrupt image/label: image size (7, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\a9fe7dbcb36994e93ecc56919a5be755_1.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\b9c46d9092ddb799c80855e16e1af793_1.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\bae97f090c5d13bf4f5557c82d6d2d4a_0.jpg: ignoring corrupt image/label: image size (9, 21) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\f31ec6705c27e98c716ce6c68d44ca76_1.jpg: ignoring corrupt image/label: image size (9, 30) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\ff36b73cf344b8634663df1bb37f2a62_1.jpg: ignoring corrupt image/label: image size (9, 16) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\content\\split\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 56.661.9 MB/s, size: 31.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\content\\split\\val\\labels... 996 images, 0 backgrounds, 3 corrupt: 100%|██████████| 999/999 [00:02<00:00, 497.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\a9fe7dbcb36994e93ecc56919a5be755_0.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\e511decc1e28e3f1c41ec70ba86110f5_1.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\ff36b73cf344b8634663df1bb37f2a62_0.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\content\\split\\val\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/3         0G     0.2073      1.765     0.9272         16        640: 100%|██████████| 499/499 [38:41<00:00,  4.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [02:07<00:00,  2.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.348      0.931      0.437      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/3         0G     0.1538      1.255     0.8914         16        640: 100%|██████████| 499/499 [50:48<00:00,  6.11s/it]    \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [01:57<00:00,  1.87s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.329      0.774      0.396      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        3/3         0G     0.1139      1.132      0.871         18        640: 100%|██████████| 499/499 [37:39<00:00,  4.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [02:01<00:00,  1.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.408      0.808      0.531      0.529\n",
            "\n",
            "3 epochs completed in 2.234 hours.\n",
            "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 5.4MB\n",
            "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 5.4MB\n",
            "\n",
            "Validating runs\\detect\\train\\weights\\best.pt...\n",
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [01:33<00:00,  1.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.407      0.808      0.531      0.529\n",
            "                   F15        310        310       0.36      0.726      0.387      0.384\n",
            "                   F16        359        359      0.468      0.794      0.627      0.626\n",
            "                   F18        327        327      0.394      0.905      0.578      0.578\n",
            "Speed: 1.3ms preprocess, 76.5ms inference, 0.0ms loss, 2.7ms postprocess per image\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('yolo11n.pt')\n",
        "dataset_yaml = '/content/dataset.yaml'\n",
        "\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=dataset_yaml,\n",
        "        epochs=3,\n",
        "        imgsz=640,\n",
        "        batch=8,\n",
        "        save=False,\n",
        "        plots=False\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq1K8qUKDaD1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDPjJqTx591O"
      },
      "source": [
        "## Training the model with various learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-sHtEdz514H",
        "outputId": "7761cd51-06b9-494a-c987-d29dce5a3306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=4, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_lr_0_01, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs\\detect\\run_lr_0_01, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 399.2479.7 MB/s, size: 834.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\content\\split\\train\\labels.cache... 3989 images, 0 backgrounds, 7 corrupt: 100%|██████████| 3996/3996 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\2957729725f0acb08acb86af5e28c5f3_0.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\8a0b8bad3da60ee3b07c0c7b5cd65213_1.jpg: ignoring corrupt image/label: image size (7, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\a9fe7dbcb36994e93ecc56919a5be755_1.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\b9c46d9092ddb799c80855e16e1af793_1.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\bae97f090c5d13bf4f5557c82d6d2d4a_0.jpg: ignoring corrupt image/label: image size (9, 21) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\f31ec6705c27e98c716ce6c68d44ca76_1.jpg: ignoring corrupt image/label: image size (9, 30) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\ff36b73cf344b8634663df1bb37f2a62_1.jpg: ignoring corrupt image/label: image size (9, 16) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 131.8142.2 MB/s, size: 31.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\content\\split\\val\\labels.cache... 996 images, 0 backgrounds, 3 corrupt: 100%|██████████| 999/999 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\a9fe7dbcb36994e93ecc56919a5be755_0.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\e511decc1e28e3f1c41ec70ba86110f5_1.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\ff36b73cf344b8634663df1bb37f2a62_0.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\run_lr_0_01\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "        1/4         0G     0.0928       1.05     0.8678         17        640: 100%|██████████| 250/250 [1:03:35<00:00, 15.26s/it]   \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:51<00:00,  3.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.378      0.846      0.477      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        2/4         0G     0.1233       1.04     0.8802         16        640: 100%|██████████| 250/250 [39:19<00:00,  9.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:43<00:00,  3.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.424      0.735      0.523      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        3/4         0G     0.1052     0.9943     0.8683         18        640: 100%|██████████| 250/250 [33:35<00:00,  8.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:48<00:00,  3.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.389      0.829      0.574       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        4/4         0G     0.0844     0.9244     0.8651         16        640: 100%|██████████| 250/250 [34:15<00:00,  8.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:41<00:00,  3.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.586      0.781      0.742      0.735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4 epochs completed in 2.965 hours.\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_01\\weights\\last.pt, 5.4MB\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_01\\weights\\best.pt, 5.4MB\n",
            "\n",
            "Validating runs\\detect\\run_lr_0_01\\weights\\best.pt...\n",
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:24<00:00,  2.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.592      0.775      0.742      0.736\n",
            "                   F15        310        310      0.459      0.819       0.65      0.635\n",
            "                   F16        359        359      0.519      0.947       0.79      0.787\n",
            "                   F18        327        327      0.798       0.56      0.786      0.785\n",
            "Speed: 1.3ms preprocess, 69.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "results = model.train(\n",
        "    data=dataset_yaml,\n",
        "    #cfg=best_hyp_yaml,\n",
        "    epochs=4,\n",
        "    imgsz=640,\n",
        "    batch=16, lr0=0.01, name=\"run_lr_0_01\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8LpMtKU6Hzq",
        "outputId": "56590498-5377-4cf0-fc8b-21b1ecae06da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=4, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.1, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_lr_0_1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs\\detect\\run_lr_0_1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 331.0401.5 MB/s, size: 834.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\content\\split\\train\\labels.cache... 3989 images, 0 backgrounds, 7 corrupt: 100%|██████████| 3996/3996 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\2957729725f0acb08acb86af5e28c5f3_0.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\8a0b8bad3da60ee3b07c0c7b5cd65213_1.jpg: ignoring corrupt image/label: image size (7, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\a9fe7dbcb36994e93ecc56919a5be755_1.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\b9c46d9092ddb799c80855e16e1af793_1.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\bae97f090c5d13bf4f5557c82d6d2d4a_0.jpg: ignoring corrupt image/label: image size (9, 21) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\f31ec6705c27e98c716ce6c68d44ca76_1.jpg: ignoring corrupt image/label: image size (9, 30) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\ff36b73cf344b8634663df1bb37f2a62_1.jpg: ignoring corrupt image/label: image size (9, 16) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 114.9121.1 MB/s, size: 31.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\content\\split\\val\\labels.cache... 996 images, 0 backgrounds, 3 corrupt: 100%|██████████| 999/999 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\a9fe7dbcb36994e93ecc56919a5be755_0.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\e511decc1e28e3f1c41ec70ba86110f5_1.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\ff36b73cf344b8634663df1bb37f2a62_0.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.1' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\run_lr_0_1\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/4         0G    0.08235     0.8499     0.8648         17        640: 100%|██████████| 250/250 [1:05:01<00:00, 15.61s/it]  \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:44<00:00,  3.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.556      0.764      0.713       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        2/4         0G     0.1044     0.8735     0.8717         16        640: 100%|██████████| 250/250 [36:32<00:00,  8.77s/it]   \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:01<00:00,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.512      0.796        0.7      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        3/4         0G    0.09799     0.8442     0.8649         18        640: 100%|██████████| 250/250 [19:43<00:00,  4.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:08<00:00,  2.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.475      0.755      0.655      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        4/4         0G     0.0772     0.7854     0.8632         16        640: 100%|██████████| 250/250 [20:43<00:00,  4.97s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:02<00:00,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.707      0.778      0.843      0.828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4 epochs completed in 2.450 hours.\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_1\\weights\\last.pt, 5.4MB\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_1\\weights\\best.pt, 5.4MB\n",
            "\n",
            "Validating runs\\detect\\run_lr_0_1\\weights\\best.pt...\n",
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:53<00:00,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.707      0.776      0.843      0.828\n",
            "                   F15        310        310      0.579      0.839      0.794       0.76\n",
            "                   F16        359        359      0.721      0.852      0.879      0.876\n",
            "                   F18        327        327      0.823      0.638      0.855      0.849\n",
            "Speed: 0.9ms preprocess, 47.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = model.train(\n",
        "    data=dataset_yaml,\n",
        "    #cfg=best_hyp_yaml,\n",
        "    epochs=4,\n",
        "    imgsz=640,\n",
        "    batch=16, lr0=0.1, name=\"run_lr_0_1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqy8lcLZ6Mph",
        "outputId": "f1c5aa1d-1f88-4e88-b72c-87b77b3e36a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=4, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_lr_0_001, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs\\detect\\run_lr_0_001, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1088.01146.5 MB/s, size: 834.7 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\content\\split\\train\\labels.cache... 3989 images, 0 backgrounds, 7 corrupt: 100%|██████████| 3996/3996 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\2957729725f0acb08acb86af5e28c5f3_0.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\8a0b8bad3da60ee3b07c0c7b5cd65213_1.jpg: ignoring corrupt image/label: image size (7, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\a9fe7dbcb36994e93ecc56919a5be755_1.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\b9c46d9092ddb799c80855e16e1af793_1.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\bae97f090c5d13bf4f5557c82d6d2d4a_0.jpg: ignoring corrupt image/label: image size (9, 21) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\f31ec6705c27e98c716ce6c68d44ca76_1.jpg: ignoring corrupt image/label: image size (9, 30) <10 pixels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\content\\split\\train\\images\\ff36b73cf344b8634663df1bb37f2a62_1.jpg: ignoring corrupt image/label: image size (9, 16) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 324.4314.7 MB/s, size: 31.9 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\content\\split\\val\\labels.cache... 996 images, 0 backgrounds, 3 corrupt: 100%|██████████| 999/999 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\a9fe7dbcb36994e93ecc56919a5be755_0.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\e511decc1e28e3f1c41ec70ba86110f5_1.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\ff36b73cf344b8634663df1bb37f2a62_0.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\run_lr_0_001\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/4         0G    0.07419     0.7089     0.8619         17        640: 100%|██████████| 250/250 [21:03<00:00,  5.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:11<00:00,  2.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.688      0.749      0.808      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        2/4         0G     0.1009     0.7625     0.8711         16        640: 100%|██████████| 250/250 [28:55<00:00,  6.94s/it]  \n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:05<00:00,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.494      0.765      0.692      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        3/4         0G    0.09447     0.7462     0.8634         18        640: 100%|██████████| 250/250 [20:49<00:00,  5.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:15<00:00,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.637      0.737      0.763      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "        4/4         0G    0.07369     0.6986     0.8617         16        640: 100%|██████████| 250/250 [25:24<00:00,  6.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [01:06<00:00,  2.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.738      0.782      0.843      0.817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4 epochs completed in 1.681 hours.\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_001\\weights\\last.pt, 5.4MB\n",
            "Optimizer stripped from runs\\detect\\run_lr_0_001\\weights\\best.pt, 5.4MB\n",
            "\n",
            "Validating runs\\detect\\run_lr_0_001\\weights\\best.pt...\n",
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:55<00:00,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.738       0.78      0.843      0.816\n",
            "                   F15        310        310      0.621      0.816      0.781      0.734\n",
            "                   F16        359        359      0.858      0.706      0.882       0.86\n",
            "                   F18        327        327      0.734      0.817      0.867      0.855\n",
            "Speed: 0.9ms preprocess, 49.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = model.train(\n",
        "    data=dataset_yaml,\n",
        "    #cfg=best_hyp_yaml,\n",
        "    epochs=4,\n",
        "    imgsz=640,\n",
        "    batch=16, lr0=0.001, name=\"run_lr_0_001\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oIuhC3aJu1n"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4N988qWl8k",
        "outputId": "38cdbe79-9188-499f-fffa-c8b2d60c37cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.165  Python-3.11.9 torch-2.7.1+cpu CPU (13th Gen Intel Core(TM) i5-1334U)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 902.8894.6 MB/s, size: 278.4 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\content\\split\\val\\labels.cache... 996 images, 0 backgrounds, 3 corrupt: 100%|██████████| 999/999 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\a9fe7dbcb36994e93ecc56919a5be755_0.jpg: ignoring corrupt image/label: image size (7, 11) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\e511decc1e28e3f1c41ec70ba86110f5_1.jpg: ignoring corrupt image/label: image size (9, 20) <10 pixels\n",
            "\u001b[34m\u001b[1mval: \u001b[0mC:\\content\\split\\val\\images\\ff36b73cf344b8634663df1bb37f2a62_0.jpg: ignoring corrupt image/label: image size (9, 18) <10 pixels\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "C:\\Users\\tanuj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [01:01<00:00,  1.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        996        996      0.733      0.776      0.842      0.815\n",
            "                   F15        310        310      0.619       0.81      0.776      0.728\n",
            "                   F16        359        359      0.857      0.699      0.879      0.859\n",
            "                   F18        327        327      0.724       0.82       0.87      0.857\n",
            "Speed: 0.8ms preprocess, 51.6ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Try to find the best.pt file in available runs\n",
        "# Update this path to where your runs are actually saved\n",
        "run_dirs = glob.glob('C:/Users/tanuj/Downloads/runs/detect/*/weights/best.pt')\n",
        "if not run_dirs:\n",
        "\traise FileNotFoundError(\"No 'best.pt' file found in any run directory. Please check your training runs path.\")\n",
        "MODEL_PATH = run_dirs[0]  # Use the first found model, or select as needed\n",
        "\n",
        "dataset_yaml = '/content/dataset.yaml'\n",
        "model = YOLO(MODEL_PATH)\n",
        "results = model.val(data=dataset_yaml, plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkttcXlx-5mb",
        "outputId": "8022ad03-ab18-434b-8108-272c40df1f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Learning Rate  mAP@0.5  mAP@0.5:0.95  Precision   Recall\n",
            "0          0.001  0.84318       0.81699    0.73797  0.78198\n",
            "1          0.010  0.74233       0.73540    0.58604  0.78137\n",
            "2          0.100  0.84284       0.82820    0.70673  0.77843\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use run_dirs to get the correct experiment folders and learning rates\n",
        "run_dir_map = {\n",
        "    'run_lr_0_001': 0.001,\n",
        "    'run_lr_0_01': 0.01,\n",
        "    'run_lr_0_1': 0.1\n",
        "}\n",
        "\n",
        "metrics = []\n",
        "\n",
        "for run_path in run_dirs:\n",
        "    # Extract experiment name from the path\n",
        "    exp_name = os.path.basename(os.path.dirname(os.path.dirname(run_path)))\n",
        "    if exp_name not in run_dir_map:\n",
        "        continue\n",
        "    lr = run_dir_map[exp_name]\n",
        "    exp_dir = os.path.dirname(os.path.dirname(run_path))\n",
        "    csv_path = os.path.join(exp_dir, 'results.csv')\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"results.csv not found for {exp_name} at {csv_path}\")\n",
        "        continue\n",
        "    df_temp = pd.read_csv(csv_path)\n",
        "    best_idx = df_temp['metrics/mAP50(B)'].idxmax()\n",
        "    row = df_temp.loc[best_idx]\n",
        "\n",
        "    metrics.append({\n",
        "        'Learning Rate': lr,\n",
        "        'mAP@0.5': row['metrics/mAP50(B)'],\n",
        "        'mAP@0.5:0.95': row['metrics/mAP50-95(B)'],\n",
        "        'Precision': row['metrics/precision(B)'],\n",
        "        'Recall': row['metrics/recall(B)']\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(metrics)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "-24nO7j-AGxg",
        "outputId": "71eceecb-7411-4b10-f3e6-c12b8ca5632a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Learning Rate'], df['mAP@0.5'], label='mAP@0.5', marker='o')\n",
        "plt.plot(df['Learning Rate'], df['mAP@0.5:0.95'], label='mAP@0.5:0.95', marker='o')\n",
        "plt.plot(df['Learning Rate'], df['Precision'], label='Precision', marker='o')\n",
        "plt.plot(df['Learning Rate'], df['Recall'], label='Recall', marker='o')\n",
        "\n",
        "plt.xscale('log')  # Optional: log scale makes learning rates easier to visualize\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Score')\n",
        "plt.title('YOLO Validation Metrics vs Learning Rate')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gmWxNCxAF2t"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo7jsXLVLarP"
      },
      "source": [
        "# Saving the Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmNCdtqkLaRP",
        "outputId": "e929ed49-3e4b-46ac-c5fd-d88d728d5350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z7OtcwqMD0p"
      },
      "outputs": [],
      "source": [
        "# This creates a project folder in your Drive and copies the runs folder into it\n",
        "!mkdir -p /content/drive/MyDrive/YOLO_Aircraft_Project/\n",
        "!cp -r /content/runs /content/drive/MyDrive/YOLO_Aircraft_Project/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_oIuhC3aJu1n"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
