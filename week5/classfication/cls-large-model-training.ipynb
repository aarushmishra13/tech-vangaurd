{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial preparations"
      ],
      "metadata": {
        "id": "lme5xP6T_19u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c3uigjxcCkN"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMaJvw6BNhEj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neN716xdMkwS"
      },
      "source": [
        "# Unzip the Dataset & Add artificial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3ae9079"
      },
      "outputs": [],
      "source": [
        "!unzip ./drive/MyDrive/vang/classification_dataset.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFLWOd1zQZdU"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision opencv-python tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0fdpDU2GRQL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIG ---\n",
        "DATA_DIR = Path(\"classification_dataset/train\")\n",
        "MIN_IMAGES = 200\n",
        "EXTS = [\".jpg\", \".jpeg\", \".png\"]\n",
        "\n",
        "# --- Augmentation pipeline ---\n",
        "base_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(512, scale=(0.8, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomVerticalFlip(p=0.2),\n",
        "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.02),\n",
        "    T.RandomRotation(degrees=15),\n",
        "    T.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05), shear=5),\n",
        "])\n",
        "\n",
        "def apply_custom_augment(img):\n",
        "    img = base_transforms(img)\n",
        "    if random.random() < 0.3:\n",
        "        img = img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n",
        "    if random.random() < 0.3:\n",
        "        enhancer = ImageEnhance.Sharpness(img)\n",
        "        img = enhancer.enhance(random.uniform(0.5, 2.0))\n",
        "    return img\n",
        "\n",
        "# --- Count images ---\n",
        "def count_images(class_dir):\n",
        "    return len([f for f in class_dir.iterdir() if f.suffix.lower() in EXTS])\n",
        "\n",
        "# --- Augment one class ---\n",
        "def augment_class_dir(class_dir, before):\n",
        "    imgs = [f for f in class_dir.iterdir() if f.suffix.lower() in EXTS]\n",
        "    count = before\n",
        "    i = 0\n",
        "\n",
        "    while count < MIN_IMAGES:\n",
        "        src_img_path = random.choice(imgs)\n",
        "        try:\n",
        "            img = Image.open(src_img_path).convert('RGB')\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        augmented = apply_custom_augment(img)\n",
        "        aug_name = f\"{src_img_path.stem}_aug_{i}.jpg\"\n",
        "        augmented.save(class_dir / aug_name, quality=95)\n",
        "        count += 1\n",
        "        i += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "# --- Main ---\n",
        "def main():\n",
        "    print(f\"üìä Scanning dataset in {DATA_DIR}\")\n",
        "    report = []\n",
        "\n",
        "    for class_dir in sorted(DATA_DIR.iterdir()):\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "\n",
        "        class_name = class_dir.name\n",
        "        before = count_images(class_dir)\n",
        "\n",
        "        if before < MIN_IMAGES:\n",
        "            print(f\"üìà Augmenting '{class_name}': {before} ‚Üí {MIN_IMAGES}\")\n",
        "            after = augment_class_dir(class_dir, before)\n",
        "            report.append((class_name, before, after))\n",
        "        else:\n",
        "            report.append((class_name, before, before))\n",
        "\n",
        "    print(\"\\n‚úÖ Dataset Balancing Report:\")\n",
        "    for name, before, after in report:\n",
        "        status = \"‚úÖ\" if after >= MIN_IMAGES else \"‚ö†Ô∏è\"\n",
        "        print(f\"{status} {name.ljust(20)} : {str(before).rjust(4)} ‚Üí {str(after).rjust(4)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLJEnsXdVYPg"
      },
      "source": [
        "# Starting the training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial run"
      ],
      "metadata": {
        "id": "SmyCfMCH_6OW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7WK0XHI06NR"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8s-cls')\n",
        "\n",
        "model.train(\n",
        "    data='classification_dataset',\n",
        "    epochs=20,\n",
        "    imgsz=384,\n",
        "    name='cls_run_2',\n",
        "    batch=16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second run epochs 1-11 (colab ran out of resources)"
      ],
      "metadata": {
        "id": "b4n_aS7j_-qk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS8ffZ2gHvwc"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8l-cls.pt')\n",
        "\n",
        "\n",
        "model.train(\n",
        "    data='classification_dataset',    # cleaned dataset path\n",
        "    project='/content/drive/MyDrive/yolo_classification_checkpoints',\n",
        "    name='cls_drive_run_w_augmented',\n",
        "\n",
        "    # Core training loop\n",
        "    epochs=50,                        # plenty of time to converge\n",
        "    batch=16,                         # T4 can handle ~12 @ 640; drop to 8 if OOM\n",
        "    imgsz=512,                        # high-res for subtle features\n",
        "\n",
        "    # Checkpointing & early stop\n",
        "    save_period=5,                    # checkpoint every 5 epochs\n",
        "    patience=10,                      # early stop after 10 stagnating epochs\n",
        "\n",
        "    # Learning rate schedule\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    cos_lr=True,                   # cosine decay\n",
        "\n",
        "    optimizer='AdamW',                # smoother convergence than SGD\n",
        "\n",
        "    # Augmentation (leave on)\n",
        "    augment=True,                     # default YOLO aug pipeline\n",
        "    fliplr=0.5,                       # horizontal flips\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    translate=0.1, scale=0.5,         # slight spatial aug\n",
        "    degrees=10,\n",
        "\n",
        "    # Data loading & verbosity\n",
        "    workers=4,                        # parallel data loading\n",
        "    device='cuda:0',\n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third run epochs 11-13 (colab stopped working)"
      ],
      "metadata": {
        "id": "ngM0ZikQAAht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('last_aug_1.pt')\n",
        "\n",
        "\n",
        "model.train(\n",
        "    data='classification_dataset',    # cleaned dataset path\n",
        "    project='/content/drive/MyDrive/yolo_classification_checkpoints',\n",
        "    name='cls_drive_run_w_augmented',\n",
        "\n",
        "    # Core training loop\n",
        "    epochs=39,                        # plenty of time to converge\n",
        "    batch=16,                         # T4 can handle ~12 @ 640; drop to 8 if OOM\n",
        "    imgsz=512,                        # high-res for subtle features\n",
        "\n",
        "    # Checkpointing & early stop\n",
        "    save_period=5,                    # checkpoint every 5 epochs\n",
        "    patience=10,  # early stop after 10 stagnating epochs\n",
        "    resume=True,\n",
        "    # Learning rate schedule\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    cos_lr=True,                   # cosine decay\n",
        "\n",
        "    optimizer='AdamW',                # smoother convergence than SGD\n",
        "\n",
        "    # Augmentation (leave on)\n",
        "    augment=True,                     # default YOLO aug pipeline\n",
        "    fliplr=0.5,                       # horizontal flips\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    translate=0.1, scale=0.5,         # slight spatial aug\n",
        "    degrees=10,\n",
        "\n",
        "    # Data loading & verbosity\n",
        "    workers=4,                        # parallel data loading\n",
        "    device='cuda:0',\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "g1_W_q31mNKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final training run epochs 13-18"
      ],
      "metadata": {
        "id": "SXErSWa_ACNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('last_aug_2.pt')\n",
        "\n",
        "\n",
        "model.train(\n",
        "    data='classification_dataset',    # cleaned dataset path\n",
        "    project='/content/drive/MyDrive/yolo_classification_checkpoints',\n",
        "    name='cls_drive_run_w_augmented_v3',\n",
        "\n",
        "    # Core training loop\n",
        "    epochs=34,                        # plenty of time to converge\n",
        "    batch=16,                         # T4 can handle ~12 @ 640; drop to 8 if OOM\n",
        "    imgsz=512,                        # high-res for subtle features\n",
        "\n",
        "    # Checkpointing & early stop\n",
        "    save_period=5,                    # checkpoint every 5 epochs\n",
        "    patience=10,  # early stop after 10 stagnating epochs\n",
        "    resume=True,\n",
        "    # Learning rate schedule\n",
        "    lr0=0.001,\n",
        "    lrf=0.01,\n",
        "    cos_lr=True,                   # cosine decay\n",
        "\n",
        "    optimizer='AdamW',                # smoother convergence than SGD\n",
        "\n",
        "    # Augmentation (leave on)\n",
        "    augment=True,                     # default YOLO aug pipeline\n",
        "    fliplr=0.5,                       # horizontal flips\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    translate=0.1, scale=0.5,         # slight spatial aug\n",
        "    degrees=10,\n",
        "\n",
        "    # Data loading & verbosity\n",
        "    workers=4,                        # parallel data loading\n",
        "    device='cuda:0',\n",
        "    verbose=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "zu-8FBfRf2kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting testing the model"
      ],
      "metadata": {
        "id": "e4BDQ64S_wNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE6aiBS2Bkn6"
      },
      "outputs": [],
      "source": [
        "!pip install pillow numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZexN1-NC06-a"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def detect_and_crop_objects(model, image_path, confidence_threshold=0.5, padding=10,\n",
        "                          iou_threshold=0.45, max_detections=300):\n",
        "\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Image dimensions: {image.shape}\")\n",
        "\n",
        "    results = model(image_path, conf=confidence_threshold, iou=iou_threshold, max_det=max_detections)\n",
        "\n",
        "    cropped_images = []\n",
        "\n",
        "    # Process results\n",
        "    for i, result in enumerate(results):\n",
        "        boxes = result.boxes\n",
        "\n",
        "        if boxes is not None:\n",
        "            # Get detection data\n",
        "            xyxy = boxes.xyxy.cpu().numpy()  # Bounding boxes in xyxy format\n",
        "            conf = boxes.conf.cpu().numpy()  # Confidence scores\n",
        "            cls = boxes.cls.cpu().numpy()    # Class IDs\n",
        "\n",
        "            # print(f\"Found {len(xyxy)} objects in the image\")\n",
        "\n",
        "            # Debug: Print all detection info\n",
        "            for j, (box, confidence, class_id) in enumerate(zip(xyxy, conf, cls)):\n",
        "                x1, y1, x2, y2 = box\n",
        "                width = x2 - x1\n",
        "                height = y2 - y1\n",
        "                area_ratio = (width * height) / (image.shape[0] * image.shape[1])\n",
        "\n",
        "                class_name = model.names.get(int(class_id), f\"class_{int(class_id)}\")\n",
        "                # print(f\"Detection {j+1}: {class_name}\")\n",
        "                # print(f\"  Bbox: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\")\n",
        "                # print(f\"  Size: {width:.1f}x{height:.1f} (area: {area_ratio:.3f} of image)\")\n",
        "                # print(f\"  Confidence: {confidence:.3f}\")\n",
        "                # print()\n",
        "\n",
        "            # Crop each detected object\n",
        "            for j, (box, confidence, class_id) in enumerate(zip(xyxy, conf, cls)):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                # Add padding around the object\n",
        "                x1 = max(0, x1 - padding)\n",
        "                y1 = max(0, y1 - padding)\n",
        "                x2 = min(image.shape[1], x2 + padding)\n",
        "                y2 = min(image.shape[0], y2 + padding)\n",
        "\n",
        "                # Crop the object\n",
        "                cropped_object = image[y1:y2, x1:x2]\n",
        "\n",
        "                # Convert BGR (OpenCV) to RGB (PIL)\n",
        "                cropped_rgb = cv2.cvtColor(cropped_object, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Convert to PIL Image\n",
        "                pil_image = Image.fromarray(cropped_rgb)\n",
        "                cropped_images.append(pil_image)\n",
        "\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "def classify_image(model, image):\n",
        "    \"\"\"\n",
        "    Classify a single PIL Image using a YOLO classification model\n",
        "\n",
        "    Args:\n",
        "        model: YOLO classification model (already loaded)\n",
        "        image: PIL Image object\n",
        "\n",
        "    Returns:\n",
        "        dict: Classification result with 'class_id', 'class_name', 'confidence'\n",
        "    \"\"\"\n",
        "\n",
        "    # Run inference\n",
        "    results = model(image)\n",
        "\n",
        "    # Process results\n",
        "    for result in results:\n",
        "        # Get prediction data\n",
        "        probs = result.probs  # Classification probabilities\n",
        "\n",
        "        if probs is not None:\n",
        "            # Get top prediction\n",
        "            top_idx = torch.argmax(probs.data).cpu().numpy()\n",
        "            top_conf = torch.max(probs.data).cpu().numpy()\n",
        "\n",
        "            class_name = model.names.get(int(top_idx), f\"class_{int(top_idx)}\")\n",
        "\n",
        "            return {\n",
        "                'class_id': int(top_idx),\n",
        "                'class_name': class_name,\n",
        "                'confidence': float(top_conf)\n",
        "            }\n",
        "\n",
        "    # No classification results\n",
        "    return {\n",
        "        'class_id': -1,\n",
        "        'class_name': 'unknown',\n",
        "        'confidence': 0.0\n",
        "    }\n",
        "\n",
        "\n",
        "def visualize_detections(model_path, image_path, output_path=\"detections_visualized.jpg\", confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Visualize detections with bounding boxes on the original image\n",
        "    \"\"\"\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Run inference and save annotated image\n",
        "    results = model(image_path, conf=confidence_threshold)\n",
        "\n",
        "    # Plot results\n",
        "    for i, result in enumerate(results):\n",
        "        # Save image with annotations\n",
        "        annotated_image = result.plot()\n",
        "        cv2.imwrite(output_path, annotated_image)\n",
        "        print(f\"Annotated image saved to: {output_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"./detection.pt\")\n",
        "cls_model = YOLO(\"./drive/MyDrive/yolo_classification_checkpoints/cls_drive_run_w_augmented/weights/best.pt\")\n",
        "\n",
        "crops = detect_and_crop_objects(model, \"./f35.jpg\", 0.5, 10)\n",
        "\n",
        "for crop in crops:\n",
        "  print(classify_image(cls_model, crop))\n",
        "\n"
      ],
      "metadata": {
        "id": "6RfT8ZPTzJRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "neN716xdMkwS",
        "wKCA6oJMMyi6",
        "VnW14DFoRGmQ",
        "2PPzjLXk553G",
        "6utRtnm9ZzBT"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}